{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "beginner_python.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9uDrUCv2LOl6",
        "3Lajb4bNLOl9"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgzavala/dsx-cs4/blob/main/beginner_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9uDrUCv2LOl6"
      },
      "source": [
        "# Case Study 4.1 - Movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVirpJ_nLOl7"
      },
      "source": [
        "<h1 style=\"color:red;\">Note: If you close this notebook at any time, you will have to run all cells again upon re-opening it.</h1>\n",
        "\n",
        "<h1 style=\"color:red;\">Note: You may get different numerical results running the notebook different times. This is to be expected, you can just report whatever results you get.</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lajb4bNLOl9"
      },
      "source": [
        "# BEGINNER PYTHON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_be30ugLOl-"
      },
      "source": [
        "As this is a beginner version, we include a lot of code here to help you along the way.\n",
        "\n",
        "**First, fill in your identification information below. Then, you only have to type in the answers to the questions we ask you. For the rest of the cells, just Run them by pressing the \"Run\" button above.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSBC-SqLOmA"
      },
      "source": [
        "# Identification Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEfn4QFyLOmB"
      },
      "source": [
        "# YOUR NAME              = Sergio Gerardo Zavala Mendoza\n",
        "# YOUR MITX PRO USERNAME = sg_zavala\n",
        "# YOUR MITX PRO E-MAIL   = sg_zavala@icloud.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsGROFgpLOmJ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La11FEL-LOmL"
      },
      "source": [
        "Run these cells to install all the packages you need to complete the remainder of the case study. This may take a few minutes, so please be patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INKghW47LOmL",
        "outputId": "05093aee-13b1-4804-be19-7bef99817e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install surprise==0.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/5f/528232275f6509b1fff703c9280e58951a81abe24640905de621c9f81839/pip-20.2.3-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.2.3\n",
            "Collecting surprise==0.1\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 69 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise==0.1) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise==0.1) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise==0.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise==0.1) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1670935 sha256=5081210dc1dc3be67710cf2dcb817a58464bc2ee52bf9ab276cacccb1ac964df\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/9a/41/6a57bf37eb7b50de7f8c7ca9d7053bebe0ea7c7c9bae9fa293\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN32D1D_LOmR"
      },
      "source": [
        "If you do not see any red text, then the install was successful. Yellow text is just warnings, not errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_axZS91oLOmT"
      },
      "source": [
        "Now, you must press **Kernel > Restart.** This allows the installation to take effect. Once you see the blue **Connected/Kernel ready** button in the top right, you are good to go. If you don't see that blue indicator, then your kernel may not be working properly. If this happens, try saving your work, closing the notebook and re-opening it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gKqm-2tLOmT"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1L6KI7jLOmU"
      },
      "source": [
        "Import the required tools into the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3r3vUewLOmV",
        "outputId": "484cc718-4221-4c66-fd71-cce889320769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "from surprise import Dataset, SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\n",
        "from surprise.model_selection import cross_validate, KFold\n",
        "%matplotlib inline\n",
        "print('\\n\\nImports successful!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Imports successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_9H8EEQLOmZ"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuxIU4eWLOma"
      },
      "source": [
        "Load the MovieLens data. A dialog may pop up saying **\"Dataset ml-100k could not be found. Do you want to download it? [Y/n]\"** Type Y and hit Enter to start the download process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfoDeeQaLOmb",
        "outputId": "23630a05-bf2b-41fd-ee88-9a58b3409fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "print('\\n\\nData load successful!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "\n",
            "\n",
            "Data load successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uCjCZbULOmg"
      },
      "source": [
        "We also want to get a sense of what the data looks like. Let's create a histogram of all the ratings we have in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLvTRAYbLOmg",
        "outputId": "63398ada-b849-4802-9efb-023a8e552324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# 1. Get the ratings file from the data object\n",
        "# This is just a filename that has all the data stored in it\n",
        "ratings_file = data.ratings_file\n",
        "\n",
        "# 2. Load that table using pandas, a commmon python data loading tool\n",
        "# We set the column names manually here\n",
        "col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "raw_data = pd.read_table(ratings_file, names=col_names)\n",
        "\n",
        "# 3. Get the rating column\n",
        "ratings = raw_data.rating\n",
        "\n",
        "# 4. Generate a bar plot/histogram of that data\n",
        "ratings.value_counts().sort_index().plot.bar()\n",
        "\n",
        "print('\\n\\nHistogram generation successful!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Histogram generation successful!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_badUF0SLOmj"
      },
      "source": [
        "<h1 style=\"color:red;\">QUESTION 1: DATA ANALYSIS</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmo0floRLOmk"
      },
      "source": [
        "**Describe the dataset. How many ratings are in the dataset? How would you describe the distribution of ratings? Is there anything else we should observe? Make sure the histogram is visible in the notebook.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWScUKCSLOml"
      },
      "source": [
        "Se cargaron los datos correctamente.\n",
        "El histograma de frecuencias muestra 5 categorías con una mayor tendencia  hacia los rating 3 4 y 5. La valoracióón 4 es la que más se otorga, en tanto la de menor frecuencia son la 1 y 2 respectivamente. Se observa una alta dispersión en los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbSviiPbLOml"
      },
      "source": [
        "# Model 1: Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEmEbvZ4LOmm",
        "outputId": "8cd38a5d-0edd-4775-820c-500c1f036b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create model object\n",
        "model_random = NormalPredictor()\n",
        "print('\\n\\nModel creation successful!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXvH5T5-LOmq",
        "outputId": "ac5a4bdc-1b18-44f9-9561-fb19d183bfdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
        "model_random_results = cross_validate(model_random, data, measures=['RMSE'], cv=5, verbose=True)\n",
        "print('\\n\\nModel training successful!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    1.5246  1.5187  1.5138  1.5240  1.5075  1.5177  0.0064  \n",
            "Fit time          0.12    0.16    0.16    0.16    0.17    0.15    0.02    \n",
            "Test time         0.21    0.13    0.20    0.13    0.20    0.17    0.03    \n",
            "\n",
            "\n",
            "Model training successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlUegBhPLOmu"
      },
      "source": [
        "# Model 2: User-Based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMpM0LAbLOmu",
        "outputId": "57fa7ebf-1a59-47aa-b47e-1cc8ef26f390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create model object\n",
        "model_user = KNNBasic(sim_options={'user_based': True})\n",
        "print('\\n\\nModel creation successful!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuZrpEl5LOmx",
        "outputId": "df9ab7cb-b9f6-4370-b478-e0506265d96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
        "# Note, this may have a lot of print output\n",
        "# You can set verbose=False to prevent this from happening\n",
        "model_user_results = cross_validate(model_user, data, measures=['RMSE'], cv=5, verbose=True)\n",
        "print('\\n\\nModel training successful!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9909  0.9734  0.9750  0.9783  0.9733  0.9782  0.0066  \n",
            "Fit time          0.36    0.37    0.36    0.38    0.37    0.37    0.01    \n",
            "Test time         3.52    3.47    3.57    3.49    3.55    3.52    0.04    \n",
            "\n",
            "\n",
            "Model training successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR-1U58dLOm1"
      },
      "source": [
        "# Model 3: Item-Based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih0kmfJVLOm2",
        "outputId": "fdf3dddc-401f-4924-8b36-3c928175e7ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create model object\n",
        "model_item = KNNBasic(sim_options={'user_based': False})\n",
        "print('\\n\\nModel creation successful!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB7rxTYaLOm5",
        "outputId": "62b2ebb2-6733-4148-c013-917ac1525482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
        "# Note, this may have a lot of print output\n",
        "# You can set verbose=False to prevent this from happening\n",
        "model_item_results = cross_validate(model_item, data, measures=['RMSE'], cv=5, verbose=True)\n",
        "print('\\n\\nModel training successful!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9735  0.9818  0.9727  0.9705  0.9738  0.9745  0.0038  \n",
            "Fit time          0.55    0.58    0.58    0.57    0.56    0.57    0.01    \n",
            "Test time         4.04    3.97    4.12    4.04    4.09    4.05    0.05    \n",
            "\n",
            "\n",
            "Model training successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niz5DZsxLOm8"
      },
      "source": [
        "<h1 style=\"color:red;\">QUESTION 2: COLLABORATIVE FILTERING MODELS</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aLEyPiGLOm-"
      },
      "source": [
        "**Compare the results from the user-user and item-item models. How do they compare to each other? How do they compare to our original \"random\" model? Can you provide any intuition as to why the results came out the way they did?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTBzD0XGLOm-"
      },
      "source": [
        "\n",
        "El Modelo 1 Random,  tiene un RMSE de 1.5177 \n",
        "\n",
        "El Modelo 2 User-Based . .    RMSE de 0.9782 y std 0.0066\n",
        "\n",
        "El Modelo 3 Item-Based        RMSE de  0.9745 y std 0.0038\n",
        "\n",
        "En este caso y en mi opinión los modelos 2 y 3 son muy similares, aunque el modelo basado en Item es ligeramente mejor.\n",
        "Basados  en el criterio de la Raiz del error cuadrático medio el mejor modelo es el de filtrado colaborativo basado en Items.\n",
        "Los modelos 2 y 3 tienen mucho mejor desempeño que el modelo Random. intuitivamente se debe a las variaciones en la dispersión de los datos por lo que los dos úúltimos modelos tienen mejor desempeño y elagoritmo random usa cualquiera de las 5 recomendaciones al azar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE8jyzTxLOnA"
      },
      "source": [
        "# Model 4: Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hgU4KXXLOnA",
        "outputId": "01ca6f94-ce97-42e1-883e-1d6fabc971c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create model object\n",
        "model_matrix = SVD()\n",
        "print('\\n\\nModel creation successful!')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDwmH3ijLOnD",
        "outputId": "352a872a-960e-48e2-886e-28517a39b17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
        "# Note, this may take some time (2-3 minutes) to train, so please be patient\n",
        "model_matrix_results = cross_validate(model_matrix, data, measures=['RMSE'], cv=5, verbose=True)\n",
        "print('\\n\\nModel training successful!')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9345  0.9309  0.9335  0.9390  0.9446  0.9365  0.0048  \n",
            "Fit time          4.98    4.99    4.99    5.02    5.02    5.00    0.02    \n",
            "Test time         0.14    0.24    0.14    0.14    0.22    0.18    0.05    \n",
            "\n",
            "\n",
            "Model training successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b64hK2FwLOnG"
      },
      "source": [
        "<h1 style=\"color:red;\">QUESTION 3: MATRIX FACTORIZATION MODEL</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lithWCImLOnG"
      },
      "source": [
        "**The matrix factorization model is different from the collaborative filtering models. Briefly describe this difference. Also, compare the RMSE again. Does it improve? Can you offer any reasoning as to why that might be?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkny8CXyLOnH"
      },
      "source": [
        "La matriz de factorización es un modelo de filtrado coalaborativo. A diferencia de los modelos usuario-usuario/ítem, que usan la similitud entre usuario o items, el modelo de la matriz de factorización utiliza la factorizacióón de bajo rango buscando las similitudes entre las preferencias de los usuarios para realizar las recomendaciones.\n",
        "el RMSE para este modelo (0.9365) es significativamente mejor que en los modelos anteriores, debido a que ofrece un mayor nivel de personalización al indentificar la similitudes entre usuarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5mrElp7LOnI"
      },
      "source": [
        "# Precision and Recall @ `k`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYrHhANLOnJ"
      },
      "source": [
        "We now want to compute the precision and recall for 2 values of `k`: 5 and 10. We have provided some code here to help you do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g66bd9bLOnJ"
      },
      "source": [
        "First, we define a function that takes in some predictions, a value of `k` and a threshold parameter. This code is adapted from [here](http://surprise.readthedocs.io/en/stable/FAQ.html?highlight=precision#how-to-compute-precision-k-and-recall-k). **Make sure you run this cell.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XGXCDKGLOnJ",
        "outputId": "a2b30aa9-c5e7-45b3-b857-c7730e9a35e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    '''Return precision and recall at k metrics for each user.'''\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = dict()\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        current = user_est_true.get(uid, list())\n",
        "        current.append((est, true_r))\n",
        "        user_est_true[uid] = current\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "print('\\n\\nFunction creation successful!')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Function creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZoCJ2WLOnM"
      },
      "source": [
        "Next, we compute the precision and recall at `k` = 5 and 10 for each of our 4 models. We use 5-fold cross validation again to average the results across the entire dataseat.\n",
        "\n",
        "Please note that this will take some time to compute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVpZg93BLOnN"
      },
      "source": [
        "<h1 style=\"color:red;\">QUESTION 4: PRECISION/RECALL</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPpIGhCWLOnN"
      },
      "source": [
        "**Compute the precision and recall, for each of the 4 models, at `k` = 5 and 10. This is 2 x 2 x 4 = 16 numerical values. Do you note anything interesting about these values? Anything differerent from the RMSE values you computed above?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFeFL-jJLOnN"
      },
      "source": [
        "RMSE Evalua la calidad de la predicción, en tanto precisión and recall evaluan la calidad de la recomendación.\n",
        "Se busca tener el menor RMSE y la mayor presicióón. Ésta última indicará el  porcentaje de veces que se hace una recomendacióón adecuada.\n",
        "\n",
        "\n",
        "k=5 . .   Random . .   User . .   Item . .  Matrix\n",
        "\n",
        "precision . . 0.588 . .0.763 . . 0.817 . . 0.783\n",
        "\n",
        "recall . . 0.335 . . 0.454 . . 0.389 . . 0.434\n",
        "\n",
        "k=10 . .    Random . .   User . .   Item . .  Matrix\n",
        "\n",
        "precision . . 0.584 . . 0.740 . . 0.788 . . 0.756\n",
        "\n",
        "recall . . 0.434 . . 0.592 . . 0.532 . . 0.560\n",
        "\n",
        "\n",
        "Al igual que en los resultadoa anteriores sin integrar el modelo de Matrix, el algoritmo con el mejor predictor y mejor presición fue el  modelo colaborativo basado en el Item..\n",
        "llama la atención que el modelo de Matrix aunque tiene un RSME mejor, no logra superar ni en presición ni en exaustividad al modelo basado en ITEM.\n",
        "\n",
        "Abajo el Código y los resultados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzgDwFkPLOnO",
        "outputId": "21349706-1102-41e4-984b-043a0b6f12e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make list of k values\n",
        "K = [5, 10]\n",
        "\n",
        "# Make list of models\n",
        "models = [model_random, model_user, model_item, model_matrix]\n",
        "\n",
        "# Create k-fold cross validation object\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "for k in K:\n",
        "    for model in models:\n",
        "        print(f'>>> k={k}, model={model.__class__.__name__}')\n",
        "        # Run folder and take average\n",
        "        p = []\n",
        "        r = []\n",
        "        for trainset, testset in kf.split(data):\n",
        "            model.fit(trainset)\n",
        "            predictions = model.test(testset, verbose=False)\n",
        "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5)\n",
        "\n",
        "            # Precision and recall can then be averaged over all users\n",
        "            p.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
        "            r.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
        "        \n",
        "        print('>>> precision:', round(sum(p) / len(p), 3))\n",
        "        print('>>> reccall  :', round(sum(r) / len(r), 3))\n",
        "        print('\\n')\n",
        "\n",
        "print('\\n\\nPrecision and recall computation successful!')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> k=5, model=NormalPredictor\n",
            ">>> precision: 0.588\n",
            ">>> reccall  : 0.335\n",
            "\n",
            "\n",
            ">>> k=5, model=KNNBasic\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            ">>> precision: 0.763\n",
            ">>> reccall  : 0.454\n",
            "\n",
            "\n",
            ">>> k=5, model=KNNBasic\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            ">>> precision: 0.817\n",
            ">>> reccall  : 0.389\n",
            "\n",
            "\n",
            ">>> k=5, model=SVD\n",
            ">>> precision: 0.783\n",
            ">>> reccall  : 0.434\n",
            "\n",
            "\n",
            ">>> k=10, model=NormalPredictor\n",
            ">>> precision: 0.584\n",
            ">>> reccall  : 0.434\n",
            "\n",
            "\n",
            ">>> k=10, model=KNNBasic\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            ">>> precision: 0.74\n",
            ">>> reccall  : 0.592\n",
            "\n",
            "\n",
            ">>> k=10, model=KNNBasic\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            ">>> precision: 0.788\n",
            ">>> reccall  : 0.532\n",
            "\n",
            "\n",
            ">>> k=10, model=SVD\n",
            ">>> precision: 0.756\n",
            ">>> reccall  : 0.56\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Precision and recall computation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAS4i8eNLOnR"
      },
      "source": [
        "#  Top-`n` Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DepL_vAsLOnR"
      },
      "source": [
        "Finally, we can see what some of the actual movie ratings are for particular users, as outputs of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfTM0uDGLOnS"
      },
      "source": [
        "Again, we define a helpful function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU25CzXkLOnS",
        "outputId": "d3fe2082-8e4e-420b-d68e-a5bc3f78dbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_top_n(predictions, n=5):\n",
        "    '''Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    '''\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = dict()\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        current = top_n.get(uid, [])\n",
        "        current.append((iid, est))\n",
        "        top_n[uid] = current\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "print('Function creation successful!')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addbM5iyLOnV"
      },
      "source": [
        "Then, we call this function on each of our models, first training on **all** the data we have available, then predicting on the remaining, missing data. We use `n`=5 here, but you can pick any reasonable value of `n` you would like.\n",
        "\n",
        "This may take some time to compute, so be patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Osn52lLOnV",
        "outputId": "e8cee0b4-350d-409b-9ff4-ca20dfa7aa8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "trainset = data.build_full_trainset()\n",
        "testset = trainset.build_anti_testset()\n",
        "print('\\n\\nTrainset and testset creation successful!')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Trainset and testset creation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNDyBk_GLOnY"
      },
      "source": [
        "<h1 style=\"color:red;\">QUESTION 5: TOP N PREDICTIONS</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ZfQ_JOLOnY"
      },
      "source": [
        "**Do the top n predictions that you received make sense? What is the rating value (1-5) of these predictions? How could you use these predictions in the real-world if you were trying to build a generic content recommender system for a company?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7imCyNDLOnZ"
      },
      "source": [
        "Las predicciones en los 4 modelos tienen sentido ya que en todos los casos el raiting value están entre 4.3076 y 5.\n",
        "Este modelo podría entrenarse para recomendar a los clientes de una tienda en linea los productos en funcióón de las preferencias de los clientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0FvNknVLOnZ",
        "outputId": "9303d175-6aef-46cf-c583-357c45732328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "for model in models:\n",
        "    model.fit(trainset)\n",
        "    predictions = model.test(testset)\n",
        "    top_n = get_top_n(predictions, n=5)\n",
        "    # Print the first one\n",
        "    user = list(top_n.keys())[0]\n",
        "    print(f'model: {model}, {user}: {top_n[user]}')\n",
        "\n",
        "print('\\n\\nTop N computation successful!')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model: <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7f22d34f6780>, 196: [('465', 5), ('387', 5), ('95', 5), ('246', 5), ('196', 5)]\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f22d0f27160>, 196: [('1189', 5), ('1500', 5), ('814', 5), ('1536', 5), ('1599', 5)]\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f22d4e67c50>, 196: [('1414', 4.666666666666667), ('1309', 4.5), ('1310', 4.5), ('1675', 4.333333333333333), ('1676', 4.3076923076923075)]\n",
            "model: <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7f22d460b240>, 196: [('408', 4.566293899639796), ('318', 4.558055431283207), ('169', 4.461277668865071), ('603', 4.45449898447024), ('483', 4.453644383132141)]\n",
            "\n",
            "\n",
            "Top N computation successful!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2J1uuugLOnc"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGYbvDIFLOnc"
      },
      "source": [
        "Great job! Now, make sure you check out the **Conclusion** section of the [instruction manual](https://courses.edx.org/asset-v1:MITxPRO+DSx+2T2018+type@asset+block@4.1_instruction_manual.html) to wrap up this case study properly."
      ]
    }
  ]
}